<h1>Stochastic time series - from foundation to edge approaches</h1> 

Last update: 07/2024

# Time series - overview
__References__:
- [A Survey on Principles, Models and Methods for Learning from Irregularly Sampled Time Series: From Discretization to Attention and Invariance](https://arxiv.org/abs/2012.00168)
- [Learning from Irregularly-Sampled Time Series: A Missing Data Perspective](https://arxiv.org/abs/2008.07599)


This summary goes beyond classical methods such as ARIMA, and starts with modern machine learning and deep learning techniques. However, some preliminary terms are common in time series analysis, no matter what techniques are employed.

A __time series__ is a set of observations taken sequentially in time. This implies, if we record the same observation over time, we end up with a time series dataset. Two main types of time series are regular (recording at a regular interval) and irregular time series. The techniques in this summary covers regular time series. 

In terms of tasks, there are three broad applications for time series analysis: time series forecasting, time series classification, and interpretation and causality. The focus of this summary is the first two applications. Causality and interpretations are covered in another summary under the causal machine learning repository.

__Data-generating process__ is the underlying process that generates a time series. Often, the DGP is generated by a stochastic process. In real world, an approximation of DGP is feasible, which is performed by a model. The model is a representation of some essential aspect of reality (DGP). While all models are unrealistic, some are useful. Different types of __models__ are used based on situation and objective. 

## different types of time series

__White noise__: a sequence of random numbers with zero mean and constant standard deviation.

__Red noise__: a sequence of random numbers which  has zero mean and constant variance but is serially correlated in time.

Example: $x_{t+1} = rx_t + (1-r^2)^{0.5}  w$, where $w$ is a random sample from a white noise distribution and $r$ is a correlation coefficient.

__Seasonal or cyclical signal__: the most common signal in a time series.

__Autoregressive signals__: refers to when the value of a time series for the current timestep is dependent on the values of the time series in the previous timesteps. This serial correlation is a key property of the AR signal, and it is parametrized by Order of serial correlation (number of previous timesteps that the signal is dependent on), and coefficient to combine the previous timesteps.


__Combination of the previous time series__

A combination of two or more series in the above, can also generate a time series. As an example, a pseudo-periodic signal with white noise and combine it with an AR signal generates a new time series.

__Stationary and non-stationary time series__

A time series is stationary when the probability distribution remains the same at every point in time.  A time series defined by standard Gaussian distribution can become non-stationary if over time the mean changes, or the variance changes.

While stationary time series is an assumption for many models, in the real world, most time series are non-stationary. 

Example of non-stationary time series
- Change in mean shows itself when we have an upward or downward trend. 
- A time series with seasonality is also non-stationary. 
- Change in variance shows itself when a time series has fluctuating variance. An example is heteroscedasticity, in which a time series starts with low variance, and variance keeps getting bigger over time.

## Predictability of a time series
It is also notable, time series are not all predictable. An example is stock price. Efficient-market hypothesis (EMH) implies  all known information about a stock price is already factored into the price of the stock. The implication of the hypothesis is that if someone can forecast accurately, many others will also be able to do that, and thereby the market price of the stock already reflects the change in price that this forecast brought about.

Three factors that helps to determine predictability of a time series are:
- understanding the DGP
- amount of data
- adequately repeating pattern

## Forecasting terminologies
- __Forecasting__: predicting the future values of a time series, with the knowledge of past (either past values and/or other related variables)
- __Multivariate forecasting__: if the problem in hand has more than one time series, that have dependencies among each other. 
- __Explanatory forecasting__: using information other than the history of variable values, to perform forecasting tasks.
- __Backtesting__:the equivalent of validation, here we use the history to evaluate a trained model. 
- __In-sample and out-sample__: in-sample refers to training data, and out-sample refers to testing data. 
- __Exogenous and endogenous variables__: Exogenous variables are parallel time series variables that are not modeled directly for output but used for modeling the time series that we are interested in. Endogenous variables are variables that are affected by other variables in the system. A purely endogenous variable is a variable that is entirely dependent on the other variables in the system. 
- __Forecast combination__: similar to ensembling in machine learning, is a process by which a function (either heuristic or learned) is used to combine multiple forecasts. 


# Processing time series
__References__
- []()
- []()
- []()

## Understanding the time series dataset

### `datetime` data type
References: [Pandas datetime offset](https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases)

Perhaps the most important preliminary action for processing a time series in pandas dataframe format is to convert the date into pandas datetime format. After that, we will have access to a whole range of features, such as slicing, getting information about the date such as min or max, creating range, add or subtract days, weeks, or other time variables, and more. 

### Missing values
References: [Pandas interpolation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.interpolate.html) and [scipy interpolation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp1d.html#scipy.interpolate.interp1d)

Handling missing data in time series requires knowledge about the data. For example, a missing order data in a time series from store orders may reflect store closure in a particular day, like Sunday. If we fill the gap with zero, model will have a false prediction for Monday's orders. On the other hand, if we give extra information to the model (such as the previous day was Sunday), the model will perform differently, and make a more accurate prediction. 

__Note__: some of pandas useful `read_csv` parameters, w.r.t. missing values are `na_values` and `keep_default_na`.

__Some imputation techniques__
- Last Observation Carried Forward or Forward Fil (`df[].bfill()`): use the last observation to fill missing values
- Mean value fill `df[].fillna(df[], mean())`: replace missing with the mean
- Linear Interpolation `df[].interpolate(method="linear")`
- Nearest Interpolation `df.interpolate(method="nearest")`: For each missing value, the closest observed value is found and is used to fill in the missing value.
- Spline, Polynomial, and Other Interpolations: `Scipy` package provides additional non-linear interpolation techniques as backend, by first fitting the model on a non-linear basis, and using it to perform imputation. While using spline or polynomial as the method in interpolate, we should always provide order as well. Example:
  - `df[].interpolate(method="spline", order=2)`
  - `df[].interpolate(method="polynomial", order=5)`

__Handling longer period of missing data__



### Compact, expanded, and wide data formats
- Compact form data is when any particular time series occupies only a single row in the pandas DataFrame â€“ that is, the time dimension is managed as an array within a DataFrame row.
- The expanded form is when the time series is expanded along the rows of a DataFrame. If there are n steps in the time series, it occupies n rows in the DataFrame. The time series identifiers and the metadata get repeated along all the rows. The time-varying features also get expanded along the rows. And instead of the start date and frequency, we have the datetime as a column.
- In the wide format, the date is represented as an index or as one of the columns and the different time series as different columns of the DataFrame.

### Time series frequency
- Finding global end: One of the most important characteristics of a time series is regular intervals, and we need to make sure to enforce regular intervals in the time series. __Best practice__ when working with multiple time series is to check the _end date_ of all the time series, and align them if they are not uniform, based on the latest date across all time series. 
- 

# Analyzing and visualizing time series data -EDA
## Components of a time series
A time series can contain some or all of the following components:
- trend: a long-term change in the mean of a time series.
- seasonal: a regular, repetitive, up-and-down fluctuations
- cyclical: Like seasonality, the cyclical component also exhibits a similar up-and-down pattern around the trend line, but instead of repeating the pattern every period, the cyclical component is irregular.
- irregular: This component is left after removing the trends, seasonality, and cyclicity from a time series.
- 
Two very common mixes of the above components are additive (sum of the above components) and multiplicative (multiplication of the above components).

While in classical time series, the irregular component is assumed to be unpredictable, with modern approaches (machine learning and deep learning) and help of exogenous variables we can predict a part or all of it. 

## Visualizing time series data
Some visualization techniques for a time series data are:
- line chart: the most basic and common visualization that is used for understanding a time series i line chart. While for a long period, the line chart could get chaotic, a macrowview of the time series in terms of trend and movement is more practical.

## Decomposing a time series
## Detecting and treating outliers




---
---
# Machine learning approach
Conventional machine learning paradigm developed a model by giving a learnable function input and desired output (true values) and through the training process fit the function to the given data. However, this is not the case for time forecasting tasks where the input variables are the history and output occurs in the feature. This is an extrapolation problem, whereas a machine learning method such as regression is an interpolation one. Employing a data-driven approach it is much harder to perform extrapolation. Another issue with machine learning methods for solving a time series forecasting task is the assumption of i.i.d., where time series breaks this assumption. As a result, prior to employing machine learning methods, the time series data needs to be casted as appropriate format that holds the i.i.d. assumption.

## Process time series dataset for machine learning methods

__Concept of lag and time-delay embedding__

Given a time series of length $L$ at time $t$, in an ideal world, each observation should be conditioned on all of the values in its past. However, it is not practical and the forecasting function is restricted to a limited lag value $m$ where $m<L$. For example, $m$ in Markov models (also called finite memory models) is called the order pof autoregression, memory size, or the receptive field. This concept is used to prepare time series dataset for a machine learning model. An arbitrary window of size $m$ extracts fixed length subsequences of time series and by sliding this window over the length of the time series we end up with the dataset. This method of encoding a time series to a dataset for machine learning models is called __time-delay embedding__. Following illustration shows a sliding window with memory size of 3. 

<img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781803246802/files/image/B17959_05_06.jpg" width="480" height="200"> [ref](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781803246802/files/image/B17959_05_06.jpg)

Employing this approach means we rely on the concept of time for temporal embedding models and assume that any values in the time series are only dependent on time. This leads to the possibility of creating new features (feature engineering) that captures not only time, but also the passage of time, periodicity of time and so on. 

## Data leakage

During feature engineering, one important consideration is data leakage, either in the form of target leakage or train-test contamination. Data leakage, if occurs, leads to poor model performance when it is used to make prediction on unseen data. 
- target leakage occurs when the information about the target leaks into some of the features in the model. During training, the model then relies heavily on those features, leading to poor generalization.
- train-test contamination occurs when there is some information leaking between the train and test sets. Such a case could occur in different stages of preprocessing, such as during splitting the train and test set, or scaling the dataset before splitting the train and test sets. 

__Identify data leakage__
- if a model preform too good to be true, it is probably because of a data leakage
- checking correlation between target and features could reveal potential data leakage
- if the weight of one or some features after training be too large compare to the other weights in the trained model, there is a high chance of data leakage

## Forecast horizon
 Forecast horizon is the number of time steps into the future we want to forecast at any point in time. When picking  the horizon, one consideration is to make sure it does not lead to data leakage. 

## Feature engineering
Feature engineering is the process of engineering features from the data to make the learning process more efficient while improving its performance. This is not required for classical methods such as ARIMA, since it is built into the model. On the other hand, machine learning methods benefit from feature engineering, since they do not explicitly understand time. In such a case, feature engineering embed the temporal aspect of time series into the dataset. Two approaches for encode time into a machine learning model are _time delay embeding_ and _temporal embedding_.



__Time delay embedding__

- __Lags (or backshift)__
  To encode time series with time-delay embedding, we can create multiple lags as timesteps before the current time. This method connects the present value to a single point in the past. This could be done in python by the following function: `df['lag_a'] = df['target'].shift(a)` in which $a$ represents the number of backshifts for creating a lag. Then the different lag values are concatenated to generate a history for a value point in the time series. 
  
  <img src="https://github.com/user-attachments/assets/bfd6036e-57e4-4aff-8ef6-142a891d6072" width="420" height="300"> [ref](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781803246802/files/image/B17959_05_06.jpg)


- __Rolling window aggregation__

  This method connects the current value to an aggregate statistic of a window in the past. Different statistics such as the mean, standard deviation, min, and max could be used for each rolling window. One consideration is that the rolling window should not include the current value to avoid data leakage.
  
  
  <img src="https://github.com/user-attachments/assets/e7341547-1865-4e60-808d-5b79b9d72e78" width="420" height="300">  [ref](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781803246802/files/image/B17959_06_03.jpg)



- __Seasonal rolling window aggregation__

  Another temporal embedding method is seasonal rolling window aggregation that takes $n$ consecutive observations in the past, and skipping a constant number of timesteps between each item in a window. This method requires parameter $m$ (seasonality period), which represents the number of timesteps after which we expect the seasonality pattern to repeat. One consideration is that the rolling window should not include the current value to avoid data leakage.
  
  <img src="https://github.com/user-attachments/assets/7af23826-4939-4e40-9d75-4b9bf512c178" width="420" height="300">[ref](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781803246802/files/image/B17959_06_04.jpg)



- __Exponentially weighted moving averages (EWMA)__

  Similar to moving average, but this method computes weighted average of values in the window. Weight is computed by applying a decay at an exponential rate: `df["ewma"]=df['column'].shift(1).ewm(alpha=0.5).mean()`
  
  <img src="https://github.com/user-attachments/assets/b8f972ac-7330-40b0-a76f-cf8180233ac8" width="420" height="300">[ref](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781803246802/files/image/B17959_06_06.jpg)


__Temporal embedding__

With temporal embedding, time by itself is embedded into features that a machine learning model then could use as an input feature. Some of the temporal embedding methods are as follow:
- __calendar feature__: consists of features that are extracted based on the calendar, such as the month, quarter, day of the year, hour, minutes, and week of year. These features capture the periodicity of time and help the ML model capture seasonality well.
- __time elapsed__: captures the passage of time in an ML model. This feature increases monotonically as time increases, giving the ML model a sense of the passage of time. An easy and efficient way to implement this is using integer representation of dates in Numpy: `df['time_elapsed'] = df['timestamp'].values.astype(np.int64)/(10**9)`
- __Fourier terms__: is another way to represent the temporal information, but on a continuous scale. 


## Resources for feature engineering
 
- [tsfeatures library](https://github.com/Nixtla/tsfeatures)
- [paper: Ben D. Fulcher 2017, Feature-based time-series analysis](https://arxiv.org/abs/1709.08055)
- [tsfresh library](https://tsfresh.readthedocs.io/en/latest/)

---
---
## Machine learning method for time series forecasting
Machine learning model tries to learn function $h$ (an approximation of an ideal function) that maps inputs to outputs: $'hat{y}=h(X,\phi)$, where $\phi$ is the model parameters. We pick $h$ from a family of functions (also called models) that performs the best out among all models. To make this process standard, the same configuration and preprocessing need to be conducted for all models, as well as evaluation approach.

### Linear regression
This is one of the the basic forecating approach for machine learning model, in which the goal is to minimize the loss. The most popular method of estimation is using ordinary least square, in which the model tries to minimize the residual sum of squares (mean square error). Assumptions in regression model are:
- The relationship between the independent and dependent variables is linear.
- The errors are normally distributed.
- The variance of the errors is constant across all the values of the independent variable.
- There is no autocorrelation in the errors.
- There is little to no correlation between independent variables (multi-collinearity).

In time series forecasting, all but the first assumption are ignore. It is also possible to fit a non-linear relation by projecting it into a  higher dimensional space, where the problem is linear. 

Regression model may not perform well for time series forecastng due to possibility of multi-colinearity, where a small change of input could result in a large change in coefficiient value or its sign. 

Plotting the coefficient of a linear regression model, after fitting the data, provides an insight to how well the model fits and possibility of overfitting (vergy large coefficient value could mean the model is overfitted or there is leakage in dataset).

__To overcome overfitting issue__ we can employ regularized linear regression model: either LESSO regression or Ridge regression.
- LESSO regression uses L1 norm to regularize a regression model.
- Ridge regression uses L2 norm to regularize a regression model.

__Regularization from geometric perspective__

From geometric perspective, L1 and L2 are measure of distance, where L2 is Euckidian distancem and L1 is Manhattan distance. When employ a regularization, it forces the coefficient to stay within a defined distance (norm) from the origin. In geometric perspective, during the optimization process we minimize the loss function within geometric shape defiend by the norm. In the following illsutration the concentric circles in the diagram are the contours of the loss function, with the innermost being the lowest. As we move outward, the loss increases. Instead of selecting $\beta_{opt}$ the regularized regression pickes $\beta$ which is within geometric norm. Even with the same MAE, MSE, and so on, ridge or lasso regression is preferred to linear regression because of the additional stability and robustness that comes with regularized regression, especially for forecasting, where multi-collinearity is almost always there. 

  <img src="https://github.com/user-attachments/assets/63fde1cc-ccf3-4ade-afdd-4630655dd3b9" width="420" height="300">[Ref.](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781803246802/files/image/B17959_08_05.jpg)



__L1 vs L2__: L1 norm (LASSO regression) produces a spase solution, while L2 pushes the coefficient of irrelevant features to zero (but not exactly zero). This is because the most optimal coefficients are at the edge of geometric shape of the employed regularization method. With L2, the circle does not have a corner and minima can lie anywhere on the edge of the most outer contour circle. The L1, on the hand, has a dimond shape with four corners, and the minima would lie on one of those corners. This makes the coefficient to be zero at optimal solution.

__Downside of using regression__: regression models only capture linear reshionships and for dataset with non-linear relashipships this model cannot provide an accurate solution.

### Decision trees
Decision trees split the feature space into different sub-spaces and fit a very simple model (such as average) to each one. There are two types of nodes in a decision tree â€“ a decision node and a leaf node. A decision node acts as if-else statement, and leaf nodes are nodes that donâ€™t have any other branches below them. A popular loss fucntion for regressio trees is square loss. Over the years, several alogirthms are proposed for implementing a decision tree model, amongwhich are ID3, C4.5, and CART. Classification and Regression Trees (CART) is one of the most popular methods, which support regression as well. 

To avoid overfitting, one approach is to cap the depth of the tree. Other hyperparameters for this purpose are minimum number of sampels required to split, and minimum decrease in cost ot carry out a split. [Ref](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)

Feature importance method in sklearn can used to investigate contribution of features to final prediction. However, it can also create a misleading. Instead employ permutation importance (`sklearn.inspection.permutation_importance`) provides a better assesment for feature importance analysis. 


### Random forest
Random forest, as an ensemble learning method, employs several base learners and provides the output by combining hte output of each model. Random forest is an example of bagging approach as an ensemple learning method that aim to mitigate and control overfitting by bootstrap sampling (sampling releatedly with replacement from a population). It trains weak learners on each of the subset. The base learners have high-variance and low-bias, but with bagging we maintaince the same level of bias on each weak learner, while reducing the variance. One consideration is that if the weak learners correlate with each other, it diminishes the benefits of bagging.

Random forest method is a modification of standard bagging approach that build a large collection of _decorrelated_ trees. Steps in random forest method are as follow:
1. Draw a bootstrap sample from the training dataset.
2. Select f features _at random_ from all the features.
3. Pick the best split just using f features and split the node into two child nodes.
4. Repeat steps 2 and 3 until we hit any of the defined stopping criteria.

Just like the feature importance in decision trees, Random Forests also have a very similar mechanism for estimating the feature importance. 

__Note__: For large datset, _XGBOOST_ implementation of random forest (`XGBRFRegressor`) performs much better than sklearn one. [Ref](https://xgboost.readthedocs.io/en/latest/tutorials/rf.html)

### Ensemble tree methods: XGBoost and LightGBM

Gradient boosting decision trees is another ensemble approach to use weak learners for creating a poweful model. In this approach, the weak learners are used in sequennce and each tries to improve the output of the previous one.

Two interdependent hyper-parameters in this approach are learning rate and number of weak learners (trees). By picking a low rating rate with more trees, we can avoid overfitting while still gives the model enough complexity to fit non-linearity in a dataset. Early stopping is also used to avoid overfittung, in which a validation dataset is used to monitor the out-of-sample performance while training the model. Training stops adding more trees to the ensemble when the out-of-sample error stops reducing. Subsampling also is used (both on rows and columns), where row sub-sampling is similar to bootstrapping and column subsampling is similar to random feature selection in random forest. XGBoost and LightGBM also benefit from L1 and L2 regularizaiton in their objective function. Among differnt implementation of the boosting method, the following are more popular ones:
- `GradientBoostingRegressor` and `HistGradientBoostingRegressor` in scikit-learn
- XGBoost by T Chen
- LightGBM from Microsoft
- CatBoost from Yandex

LigthGBM and CatBoost handle missing values natively, and support categorial features. The gradient boosting implementations have a mechanism for estimating the feature importance, which  is given by the average of split criteria reduction attributed to each feature in all the trees. There are several ways to get feature importance, and each implementation computes it differently. The most common ways of extracting are split and gain. Split computes feautres importance as the number of times a feature is used to split nodes in the trees. Gain is the total reduction in the split criterion. 





























































---
# Target transformation

In the machine learning field, concept drift is an equivalent of non-stationary phenomenon in time series. Stationary assumption for forecasting can be divided into two flavors: strict stationarity assumption, which states that all the statistical properties such as mean, std, and skewness do not change over time. Wek stationary states that mean and variance of the time series do not change with time. 
Some of the components in the target of forecasting that could negatively affect forecast and are needed to be removed are: unit-root, trend, seasonality, and heteroscedasticity.

Proper pipeline for target transformation is as follow: $$\text{Check for trend} \rightarrow \text{Apply detrending if needed} \rightarrow \text{Check for seasonality} \rightarrow \text{Remove seasonality if needed} \rightarrow \text{Check for heteroscedasticity} \rightarrow \text{apply box-cox transformation if needed} $$


## unit-root
To detect unit-root in a time series, we can employ Augmented Dickey-Fuller (ADF) test. The null hypothesis of this test states the autoregressive model of order 1 of the time series is equal to 1, and as the result the time series is not stationary (its variance changes over time). Alternative hypothesis states that the auto-regressive model if order 1 of the time series is less than 1 (it is stationary). The output of this test gives us a p-value that we can based on the confidence level reject/fail-to-reject the null hyp. 

## Remove unit-root
To remove unit-root from time series one approach is __differencing transform__, in which we compute the difference between each value in the time series and its predecessor value. Another approach for differencing transform is computing the ratio instead of subtraction.

One downside of this _differnecing transform_ is it removes scale of time series. Another drawback is during the prediction, perform an inverse operation to get the actual values for prediction. 

## Trend
Trend in time series comes in two forms: deterministic and stochastic. In deterministic form, trend is constant and we can model it. Stochastic trends inherently depend on the previous value of the time series . 

__Autoregressive model test__ : the same autoregressive model test for detecting unit-root also can be used to detect if a trend is deterministic or stochastic.

__Kendallâ€™s Tau__ is another test for detecting trend is Kendallâ€™s Tau, which measures the correlation but carried out on the ranks of the data. It is a non-parametric test (similar to Spearman's correlation) that calculates a rank correlation between two variables. The result of the test provides p-value. If p-value < confidence we can conclude the  trend is statistically significant. Sign of the $\tau$ determines if the trend is increasing or decreasing. This method also checks whether the trend that has been identified is deterministic or stochastic and calculates the direction of the trend.

__Mann-Kendall test (M-K test)__ is used to check for the presence of a monotonic upward or downward trend. It is a non-parametric test, but has two assumptions: 1. there is no auto-correlation in the time series, and 2. There is no seasonality in the time series. __To remove autocorrelation__ we can employ __pre-whiteninig__, and then perform this test. A variant of this test is implemented in `pymannkendall` that can handle a seasonal time series.

## Remove trend 
In the case of a deterministic trend, removing it improves model performance. One approach is to perform regression on the ordinal representation of time, and extract the parameters. Then using the dates, extrapolate trends in the future. 

## Seasonality
There are two popular ways to check for seasonality, apart from just eyeballing it: autocorrelation and fast Fourier transform. 

## Remove seasonality

## heteroscedasticity
A time series is heteroscedastic when the variability or dispersion of the time series varies with time. To detect heteroscedasticity, the most popular technique is __white test__. It uses an auxiliary regression task to check for constant variance. First run an initial regression using some covariates and calculate the residuals of this regression. Then, fit another regression model with these residuals as the target and the covariates used in the first regression, and their squares and cross products. The final statistic is estimated by using the r-square value of this auxiliary regression.

## Remove heteroscedasticity
Some of the options for removing heteroscedasticity are in the form of transformation:
- Log transform
- Box-Cox transform

---

# Ensemble and stacking 

## Overview
If we employ multiple forecasting models to make predictions, we need to pick a strategy to combine the results. Some of the strategies are as follow:
- best fit: pick the forecast with the best fit, defined by the evaluation metric. One drawback of this method is that a model may perform well on a validation set, but comes up short in generalization and performs poorly on the test set. Furthermore, a model does not fit time series similar to each other. This results in having inconsistency in the case when dealing with dynamic time series.
- measure of central tendency: this method uses average or median to combine forecasts. However, this is not a good strategy, as it levels the strong and weak forecasts at the same time.
- manual techniques such as trimming and skimming: trimming is done by discarding the worst forecast and using a central tendency technique on the remaining forecasts. Skimming selects only the best n forecasts and applies central tendency on them.
- heuristics-based approaches:
  - hill climbing: building solutions stage by stage. Here we select a local optimum at each stage, adopt a greedy and stage wise approach to find the solution to a computationally feasible optimization problem. One method for the greedy algorithm is hill climbing.
  - stochastic hill climbing: instead of evaluating all possible options and picking the best, in stochastic hill-climbing, a randomly picked candidate is added to the solution if it performs better than the current solution.
  - Simulated annealing: a modified version of hill climbing, in which the temperature parameter controls the probability of accepting a model. Other parameters are number of iterations, picking the initial solution (random or best), and starting and ending probabilities.
- Optimal weighted ensemble: via optimization algorithms, such as one provided by Scipy, we compute the weights for each forecast and use it to compute weighted average forecast as the final output.
- __Stacking or blending__
- Feature-Based Forecast Model Averaging (FFORMA) extracts a set of statistical features from the time series and uses it to train a machine learning model that predicts the weights in which the base forecast should be combined.
- trains a classifier to predict which of the base learners does best, given a set of statistical features extracted from the time series.

## Ensemble 

Ensemble method tries to combine a diverse set of strong learners. The idea is each model captures some properties of the problem well, such as seasonality, interaction with exogenous variables, and so on. The stacking model will be able to combine these base models into a model that learns to look toward one model for seasonality and the other for interaction. This is done by making the meta model learn the predictions of the base models. But to avoid data leakage and thereby avoid overfitting, the meta model should be trained on out-of-sample predictions. Two variation of this technique are _stacking_ and _blending_.

- __Stacking__:the meta model is trained on the entire training dataset, but with out-of-sample predictions. Steps:
  - Split the training dataset into k parts.
  - Iteratively, train the base models on k-1 parts, predict on the kth part, and save the predictions. Once this step is done, we have the out-of-sample predictions for the training dataset from all base models.
  - Train a meta model on these predictions.
- __Blending__: generates out-of-sample predictions. Steps:
  - Split the training dataset into two parts â€“ train and holdout.
  - Train the base models on the training dataset and predict on the holdout dataset.
  - Train a meta model on the validation dataset with the predictions of the base model as the features.

In most cases stacking works better, since it uses more data to train the model. Note that the assumption in ensemble technique is that the training dataset is independent and identically distributed. If the data distribution changes significantly over time, blending the holdout period performs better (the meta model is trained on the latest data and captures recent temporal changes in distribution of data).

The meta model is usually a simple model, such as linear regression, decision trees, or random forest (with low depth), as the actual work is performed by base models. 

`pystacnet` library can be used to make the process of creating multi or single- level stacked ensemble models. 

__Additional references__
- []()
- []()
- []()
- []()
- []()
- []()


---
# Global forecasting
In the global forecasting paradigm, a single model predicts a range of time series together. 



## Strategies to improve model performance

### Partitioning
This strategy involves partitioning or splitting the dataset into multiple equal parts. While the reason this method leads to improve model performance is not yet discovred some suggestions are: this method makes the job of the global model easier to learn when training, and this method increase model complexity [(Ref.)](https://arxiv.org/abs/2008.00444). There are several approaches to perform partitioning among which are the followings:

- __Random partitioning__: This method randomly splits the dataset into $p$ equal partitions and train separate model for each model.
- __Judgmental partitioning__: This method uses attributes of the time series to perform splitting. The use of feature depends on the model developer and features such as meta-feature or other characteristic of the time series such as volumen, variability, intermittency or a combination of features can be used to partition the dataset.
- __Algorithmic parititioning__: This method employs clustering to partition the data. Two approaches for clustering a time series are:
  - extracting features for each time series and use them to form clusters. Clustering techniques such as k-mean, k-medoids, or HDSCAN then can be applied to perform clustering.
  - using  dynamix time wraping (DTW) distance or other time series specific clustering techniques. One library for clustering time series is `tslearn`.













--- 
# Deep learning for time series forecasting

## Concept of encoder-decoder in deep learning and different architectures

The encoder takes in the input vector, $x$, and encodes it into a latent space. This encoded representation is called the latent vector, $z$. The decoder then takes $z$, and decodes it into the kind of output we need ($\hat{y}$). Latent space is an abstract vector space that encodes a meaningful internal representation of the feature space.

 In the context of time series forecasting, the encoder consumes the history and retains the information that is required for the decoder to generate the forecast.

### Feed-forward networks (FFNs) (also called fully connected networks)
In the time series forecasting context, an FFN can be used as an encoder as well as a decoder. As an encoder, we embed time and convert a time series problem into a regression problem before feeding it into the FFN. As a decoder, we use it on the latent vector (the output from the encoder) to get to the output (this is the most common usage of an FFN in time series forecasting). Constructing a FFN with PyTorch can be done with `nn.Sequential`.

__Example: simple FFN model__
```python
# generate time series dataset with sliding window
ts = torch.from_numpy(df['value'].values).float()
window_size = 10
ts_dataset = ts.unfold(0, window_size, 1)
ts_dataset.shape, ts_dataset[0], ts_dataset[1]

# Create FFN model
FFN_model = nn.Sequential(
    nn.Linear(in_features = window_size, out_features = 64), # (batch-size x window) --> (batch-size x 64)
    nn.ReLU(),
    nn.Linear(64, 32), # (batch-size x 64) --> (batch-size x 32)
    nn.ReLU(),
    nn.Linear(32, 1) # (batch-size x 32) --> (batch-size x 1)
    )

# Get forecast (assuming model has gone through training)
output = FFN_model(ts_dataset) # equivalent to FFN_model.forward(ts_dataset)
# output shape (11,1)
output.shape, output
```
### RNN 
RNNs are a family of neural networks specifically designed to handle sequential data. They first proposed by y Rumelhart et al. (1986). Some specific characteristics of RNN that give them the capability to process and make predictions on sequential data are parameter sharing and recurrence. PArameter sharing is when we use the same set of parameters for different parts of the model. RNN blocks can be used for both encoder and decoder, which makes them capable to handle different computation of input and output: such as many-to-one, and many-to-many. RNN employs backpropagation through time, meaning gradient backpropagation within a single unit, but through time. 

Stacked RNN: RNN are uni-directional and stacked on top of each other (the outputs of each timestep becomes input to the RNN in the next layer)

Bidirectional RNN: uses one set of input-to-hidden and hidden-to-hidden weights to process the inputs from start to end and another set to process the inputs in reverse (end to start) and concatenate the hidden states from both directions. It is in this concatenated hidden state that we apply the output equation.

RNN in torch has the following parameters:
- `input_size`: The number of expected features in the input. For univariate time series this is 1.
- `hidden_size`: Dimension of hidden state: (D*number of layers, batch size, hidden size), where D = 1 for bidirectional=False and D = 2 for bidirectional=True.
- `num_layers`: Number of TNNs that will be stacked on top of each other (default: 1)
- `nonlinearity`: such as ReLU and tanh
- `bias`: Bolean indicates whether or not add bias to the update equations (Default: True)
- `batch_first`: define order of input dimension to be one of the following (Default: False): (batch size, sequence length, number of features) or (sequence length, batch size, number of features).
- `dropout`: probability uses in a dropout layer on the outputs of each RNN layer except the last (default: 0)
- `bidirectional`: (Default: False)

There are two outputs of the RNN cell: an output and a hidden state. The output can be either (batch size, sequence length, D*hidden size) or (sequence length, batch size, D*hidden size), depending on batch_first. The hidden state has the dimension of (D*number of layers, batch size, hidden size).  

__Downside if RNN__ is vanishing or exploding gradient. This is when the gradient, as it is back propagated through the network, either shrinks to zero or explodes to a very high number. The former makes the network stop learning, while the latter makes the learning unstable.


### LSTM model
LSTM adds a memory cell to the RNN, which serves as long-term memory and is used in addition to the hidden state memory of classical RNNs. In an LSTM, multiple gates are tasked with reading, adding, and forgetting information from these memory cells. This memory cell acts as a gradient highway, allowing the gateways to pass relatively unhindered through the network. This is the key innovation that avoided vanishing gradients in RNNs ([ref](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM)).
- Input gate: The function of this gate is to decide how much information to read from the current input and previous hidden state.
- Forget gate: The forget gate decides how much information to forget from long-term memory
- Output gate: The output gate decides how much of the current cell state should be used to create the current hidden state, which is the output of the cell.


__Building a LSTM model__
- for hidden state, LSTM expects a tuple of tensors of the same dimension: (hidden state, cell state).
- LSTMs, just like RNNs, have stacked and bidirectional variants, and PyTorch handles them in the same way.

### Gated recurrent unit

 
<code style="color : orangered"> complete this section</code>
GRU is another variant of the RNN that has a much simpler structure than an LSTM (Cho et al 2014). 

### Convolution networks
- -
- -
- -
- -
- -


## Deep learning for time series: tabular regression


## Deep learning for time series: single-step-ahead recurrent neural networks

 
## Deep learning for time series: sequence-to-sequence models


## Transformers for time series

## Global models

## Specialized deep learning architectures for time series forecasting
Any learning algorithm for making predictions makes a set of assumptions, called learning bias. Every DL architecture has its own inductive biases, which is why some types of models perform better on some types of data. Designing the right kind of inductive biases makes or breaks the DL system. 

### Neural Basis Expansion Analysis for Interpretable Time Series Forecasting (N-BEATS)
NBeat is the first model that used some components from DL, and made a splash in the field by winning the M4 competition (univariate) in 2018.

Unique aspects of N-BEATs architecture
- formulating the problem as a multivariate regression problem (instead of encoder-decoder)
- using residual principle, stach many basic block to build a deeper model (150 layers)
- capable of generating human interpretable output

__Forecasting with N-BEATs__

_PyTorch Forecasting_ has `Nbeats` class ([ref](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.models.nbeats.NBeats.html)), with the following parameters:
- stack_types: This defines the number of stacks that we need to have in the N-BEATS model. This should be a list of strings (generic, trend, or seasonality) denoting the number and type of stacks. Examples include ["trend", "seasonality"], ["trend", "seasonality", "generic"], ["generic", "generic", "generic"], and so on. However, if the entire network is generic, we can just have a single generic stack with more blocks as well.
- num_blocks: This is a list of integers signifying the number of blocks in each stack that we have defined. If we had defined stack_types as ["trend", "seasonality"], and we want three blocks each, we can set num_blocks to [3,3].
- num_block_layers: This is a list of integers signifying the number of FC layers with ReLU activation in each block. The recommended value is 4 and the length of the list should be equal to the number of stacks we have defined.
- width: This sets the width or the number of units in the FC layers in each block. This is also a list of integers with lengths equal to the number of stacks defined.
- sharing: This is a list of Booleans signifying whether the weights generating the expansion coefficients are shared with other blocks in a stack. It is recommended to share the weights in the interpretable stacks and not share them in the generic stacks.
expansion_coefficient_length: This represents the size of the expansion coefficients (). Depending on the kind of block, the intuitive meaning of this parameter changes. For the trend block, this means the number of polynomials we are using in our basis functions. And for the seasonality, this lets us control how quickly the underlying Fourier basis functions vary. The Fourier basis functions are sinusoidal basis functions with different frequencies; if they have a large expansion_coefficient_length, this means that subsequent basis functions will have a larger frequency than if you had a smaller expansion_coefficient_length. This is a parameter that we can tune as a hyperparameter. A typical range can be between 2 and 10.

__Interpreting N-BEATs forecasting__

Running under interpretable mode (`mode="prediction"` to `mode="raw"`), provides more interpretability by separating the forecast into trend and seasonality


### Neural Basis Expansion Analysis for Interpretable Time Series Forecasting with Exogenous Variables (N-BEATSx)
This is an extension for N-BEATS that accepts exogenous variables. The overall structure is the same (with blocks, stacks, and residual connections) as N-BEATS.

__Forecasting with N-BEATSx__

`neuralforecast` by Nixtla has an implementation for N-BEATSx. `neuralforecast` doesnâ€™t support categorical features, and it requires encode the categorical features into numerical representations during the preprocessing stage. 





### Neural Hierarchical Interpolation for Time Series Forecasting (N-HiTS)
This model is specifically designed for long-horizon forecasting. Both Transformers based models and N-BEATS variants scale quadratically in memory and computation cost with regards to forecasting horizon length. While sharing a large part of its architecture with N-BETS, (N-HiTS has stacks of blocks arranged in a residual manner), N-HiTS differs only in the kind of blocks it uses. All the blocks in N-HiTS are generic. __N-HiTS tries to decompose the signal into multiple frequencies and forecast them separately__. Key improvements of N-HiTS are:
- Multi-rate data sampling: incorporating sub-sampling layers before the fully connected blocks so that the resolution of the input to each block is different. This is similar to smoothing the signal with different resolutions so that each block is looking at a pattern that occurs at different resolutions

  Similar to smoothing the signal with different resolution,
  
- Hierarchical interpolation: N-HiTS proposes a technique called temporal interpolation, to address issues that arise from forecasting a very long horizon. 
- Synchronizing the rate of input sampling with a scale of output interpolation across the blocks



__Forecasting with N-HiTS__

- N-HiTS is implemented in PyTorch Forecasting, with the following parameters:
- n_blocks: This is a list of integers signifying the number of blocks to be used in each stack. For instance, [1,1,1] means there will be three stacks with one block each.
- n_layers: This is either a list of integers or a single integer signifying the number of FC layers with a ReLU activation in each block. The recommended value is 2.
- hidden_size: This sets the width or the number of units in the FC layers in each block.
- static_hidden_size: The static features are encoded using an FC encoder into a dimension that is set by this parameter. We covered this in detail in the Neural Basis Expansion Analysis for Interpretable Time Series Forecasting with Exogenous Variables (N-BEATSx) section.
- shared_weights: This signifies whether the weights generating the expansion coefficients are shared with other blocks in a stack. It is recommended to share the weights in the interpretable stacks and not share them in the generic stacks.
- pooling_sizes: This is a list of integers that defines the pooling size () for each stack. This is an optional parameter, and if provided, we can have more control over how the pooling happens in the different stacks. Using an ordering of higher to lower improves results.
- pooling_mode: This defines the kind of pooling to be used. It should be either 'max' or 'average'.
- downsample_frequencies: This is a list of integers that defines the expressiveness ratios () for each stack. This is an optional parameter, and if provided, we can have more control over how the interpolation happens in the different stacks.


### Informer
The Informer model is a modification of Transformers, with the following major changes:
- Uniform Input Representation: a methodical way to capture history of a series along with other informations
- ProbSparse: based on information theory, it is used to improve model efficiency
- attention distillation: reduces computational complexity
- generative-style decoding: it generates a long-term horizon in a single forward pass (instead of employing dynamic recurrence)

__Note__ Informer model does not support exogenous variables. The only information it supports is global timestamp information and holiday information. 

Major parameters of Informer:
- label_len: This is an integer representing the number of timesteps from the input sequence to sample as a START token while decoding.
- distil: This is a Boolean flag for turning the attention distillation off and on.
- e_layers: This is an integer representing the number of encoder layers.
- d_layers: This is an integer representing the number of decoder layers.
- n_heads: This is an integer representing the number of attention heads.
- d_ff: This is an integer representing the number of kernels in the one-dimensional convolutional layers used in the encoder and decoder layers.
- activation: This is a string that takes in one of two values â€“ relu or gelu. This is the activation to be used in the encoder and decoder layers.
- factor: This is a float value that controls the sparsity of the attention calculation. For a value less than 1, it reduces the number of query-value pairs to calculate the divergence measure and reduces the number of Top-u samples taken than the standard formula for these quantities.
- dropout: This is a float between 0 and 1, which determines the strength of the dropout in the network.



### Autoformer
Autoformer is another variant of Transformers based time series model designed for handling long-term horizon forecasting. The focus of Informer is on improving computation efficiency. Autoformer focus is modified intention and couples it with aspects of the time series decomposition. One difference from Informer is using AutoCorrelation mechanism instead of ProbSparse attention that Informer uses. Also instead of attention distillation, Autoformer employs an encoder-decoder inspired by time series decomposition.

__Note__ Autoformer model does not support exogenous variables. The only information it supports is global timestamp information and holiday information. 

Major parameters of Autoformer:

### Temporal Fusion Transformer (TFT)
TFT is a high-performing, interpretable, and global DL model thoughtfully designed from the ground up to make the most efficient use of all the different kinds of information.

__Forecasting with TFT__: PyTorch Forecasting has an implementation of TFT.  The `TemporalFusionTransformer` class in PyTorch Forecasting has the following major parameters:
- hidden_size: This is an integer representing the hidden dimension across the model. This is the dimension in which all the GRNs work, the VSN, the LSTM hidden sizes, the self-attention hidden sizes, and so on. Arguably, this is the most important hyperparameter in the model.
- lstm_layers: This is an integer that determines the number of layers in the LSTMs we use in the LE Seq2Seq block.
- attention_head_size: This is an integer representing the number of attention heads.
- embedding_sizes: This is a dictionary of categorical feature names to a tuple of (cardinality, embedding size). Although the original paper suggests projecting all categorical and continuous variables to a single dimension, the PyTorch Forecasting implementation allows the flexibility to have separate dimensions for each variable.
- hidden_continuous_size: This is an integer that is the default embedding size for continuous features.
- hidden_continuous_sizes: This is a dictionary of continuous feature names to a hidden size for variable selection. This lets us override hidden_continuous_size for specific features.
- dropout: This is a float between 0 and 1, which determines the strength of the dropout in the network.

- 
### Interpretability


### Probabilistic forecasting










































































---
# Multi Step forecasting
In multi-step forecasting, the goal is to forecast the next $h$ steps($y_{t+1},\dots , y_{t+h}$). The classical statistical and econometric methods, such as ARIMA and exponential smoothing, can generate multiple timesteps as well as new approaches (machine learning and deep learning). However, there is a need to take specific strategies to perform multi-step forecasting. Some strategies to form a multi-step forecasting model are
- recursive
- direct
- joint
- hybrid recursive and direct
  - Iterative block-wise direct strategy (IBD)
  - DirRec
  - Rectify
- hybrid recursive and joint
  - RecJoint

Given a window $w_t$ that draws a window $Y_t = \[y_{1},\dots , y_{t}\]$ and forecast horizon $h$, each of the above strategies are formulated in the following.

__Recursive strategy (Multi-step in, single step out)__

During training, a single model is trained to perform single step ahead forecast: $w_t \rightarrow y_{t+1}$ the next iteration the forecast value is added to the windows and feeds into the model to generate the next forecast: $w_{t+1} \rightarrow y_{t+2}$
 

__Direct strategy (Multi-step in, single step out)__

Also called independent strategy, is popular when using machine learning approaches. Model has a single output. To achieve horizon forecasting, this approach trains $len(h)$ models on the same input windows $w_t$, and each generates an independent forecast of one value in the horizon: 

$$w_t \rightarrow model_1 \rightarrow y_{t+1}, w_t \rightarrow model_2 \rightarrow y_{t+2}, \dots, w_t \rightarrow model_h \rightarrow y_{t+h}$$. 

During the forecasting stage, the models are then fed with the same input and each generate a single value in the horizon. 

__Joint strategy (Multi-step in, Multi-step out)__

This method trains a model that gets a windows $w_t$ as input, and generates a multi-step output in the size of the horizon. MAchine-learning and deep-learning approaches are capable of performing joint strategy such as tabular regression, seq-to-seq models, attention and transformers -based models, and specialized deep learning models (N-Beat, N-HiTS, Temporal Fusion Transformer). 

__Hybrid strategies__

Some studies combine the previous three main strategies, to perform multi-step forecasting as a hybrid strategy.

- **DirRex strategy**: a combination of direct and recursive strategies. We have $len(h)$ models.
  - During the training phase, windows size $t$ is fed into the first model, and single output is generated: $w_t \rightarrow model_1 \rightarrow \hat{y_{t+1}}$. Then the output is added to the original windows and fed into the second model to generate the second value in the horizon: $w_{t+1} \rightarrow model_2 \rightarrow \hat{y_{t+2}}$. This process continues until reaching the last value in the horizon.
  - During the forecasting phase, the same procedure is performed to generate a multi-step output. One shortcoming of this method is in the case of long horizons, this approach requires training many models.
- **Iterative block-wise direct strategy (IBD)** (also called the iterative multi-SVR strategy): This model addresses the issue of long horizon forecasting in DirRect approach by dividing the horizon into $R$ blocks, each with length $L$.
  - Training phase: instead of training $len(h)$ models, we train $L$ direct models

  $$w_t \rightarrow model_1 \rightarrow y_{t+1}, w_t \rightarrow model_2 \rightarrow y_{t+2}, \dots, w_t \rightarrow model_L \rightarrow y_{t+L}$$.

  - during the forecasting phase, the $L$ trained models generate forecasts for the first $L$ timesteps. These values are then used as input to generate the next batch of forecast, until we reach the full horizon forecast.

- __Rectify strategy__: is the combination of direct and recursive strategy, that consists of two-stage strategy for training and inference.
  - During the training phase: in step.1 a model is trained to generate a single step forecast from windows $w_t$. In step 2, the forecast value is added to the windows and is used for $len(h)$ models , each generating a single-step forecast for one of the values in the horizon.
  - During the forecasting phase, at step1, the first model trained in step1 of the training phase is used recursively to generate a single forecast. The first step in recursive feeds $w_t$ into the model and generates a single step forecast $\hat{y_{t+1}}$. It is then added to the windows $w_t$ to be used as the input to the same model and generate the second forecast value $\hat{y_{t+2}}$. This process continues until we reach the horizon. In the second step, the $len(h)$ models trained in step2 of training are fed with concatenation of original windows and forecasted windows in step1, to each generate a single-step forecast corresponding to a value in the horizon.
- __RecJoint__: is the combination of recursive and joint strategy, but applies to a single-step forecasting model.
  - During the training, a single model is trained to predict a single-step output. Then the output is added to the input for training the next output, until reaching the horizon. The model jointly optimizes the entire horizon forecasts during the training. This forces the model to look at the next H timesteps and jointly optimize the entire horizon instead of the myopic one-step-ahead objective. Models such as seq-to-seq and RNN also employ this strategy.
  - During the forecasting phase, similar to recursive strategy, the model forecast the next time-step, the forecast value added to the input and fed into the model for the next step forecast, until reaching the horizon.
 
## Comparison between multi step forecasting strategies
The following table summarizes the strategies described above ([ref](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781803246802/files/image/B17959_17_09.jpg)). 

[](https://github.com/user-attachments/assets/9b833b8b-3892-4dcc-8d17-896ea74b49c1)


<img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781803246802/files/image/B17959_17_09.jpg" width="380" height="200">


- Complexity:  Recursive, Joint, RecJoint << IBD << Direct, DirRec << Rectify
- Training time: Recursive << Joint << RecJoint << IBD << Direct, DirRec << Rectify
- Inference time: Joint << Direct, Recursive, DirRec, IBD, RecJoint << Rectify


Another key element is the kind of model used. For example, the joint strategy requires a model that can generate a multi-step output. 

__Compare different blending/stacking strategies__

This [paper](https://arxiv.org/pdf/1108.3259.pdf) analysis the above methods and here is a summary of the fining: 

- bias and variance component of the error in recursive strategy accumulates as we go further into the horizon. As a result, direct strategy performs better in this area.
- Direct strategy, due to independence of models, could produce inconsistent output. Also it cannot capture dependency between forecasts in the horizon, and the outcome could be in the form of a broken curve.
- Joint strategy does not have the issue of generating unrelated forecast (as mentioned above for direct strategy)
- A weakness of joint strategy is its high bias for short time series.
- Joint and RecJoint both have similar variance, while joint strategy has lower bias.
- In most cases, direct strategy generates a more coherent forecast.
- bias for the recursive strategy amplifies when the forecasting model produces forecasts that have large variations. This is more prevalent in the case of employing complex models, which have high variance and low bias.
- in the case of _large dataset_ bias, the term of error in direct strategy goes to zero, but recursive strategy will have a non-zero bias.
- Recursive strategy has the following advantage, compare with direct strategy:
  - in the case of non-linear and noisy time series, recursive works better
  - if the underlying DGP be very smooth and easy to approximate, recursive strategy works better
  - recursive strategy works better in the case of short time series
- hybrid strategies try to balance the merits of the fundamental strategies, while mitigating their shortcomings. 

---
# Evaluating a forecasting model
Evaluation metrics in this section focus on point prediction. 

## Taxonomy of forecast error measures

Factors that distinguish the metrics in time series forecasting are:
- temporal relevance: this is an essential part of a forecasting and metrics such as bias and tracking a signal focus on this aspect of a forecast.
- aggregate metrics: in the case of forecasting multiple time series (related or unrelated) metric requires to capture the idiosyncrasies of this mix of time series, which is the focus of aggregate metrics.
- over and under forecasting: when over or/and under forecast is combined with the temporal aspect of time series, leads to error accumulation.

Metrics could be divided into intrinsic and extrinsic, which each are then divided into subcategories. 
- intrinsic metrics: employs the prediction and actual target values as input. Some of the metrics in this category are: absolute error, squared error, percent error, symmetric error, other metrics such forecast bias (CFE) and tracking signal
- extrinsic metrics: takes external reference or benchmark in addition to the generated forecast and ground truth to measure the quality of the forecast. Some of the metrics in this category are: relative error, scaled error, other metrics such as  PB

### Intrinsic metrics
__Absolute error__ = $|y_t - \hat{y_t}|$.  The absolute error is a scale-dependent error (magnitude of the error depends on the scale of the time series). This can cause problems in a case in which the errors are aggregated or compared across multiple time-series. The scale-dependent errors skew the metric in favor of the large-scale time series. Some of the metrics that are based on this error are
- Mean absolute error
- median absolute error
- geometric mean absolute
- weighted mean absolute error 
- normalized deviation

__Squared error__ = $(y_t - \hat{y_t})^2$. This error is also scale-dependent. Metrics that are based on this error are:
- Mean square error
- Root mean square error
- geometric root mean square error
- normalized root mean square error: similar to ND metric, but it take the square root of the squared errors in the numerator rather than the absolute error


__Percent error__ = $\frac{100(y_t - \hat{y_t})}{y_t}$: a scale-free error measure. In which the actual time series observations are used to scale the error. One downside of this error is it is asymmetrical and if actual observation is zero, the metrics based on this error does not work. Some of metric that are based on this error are:
- Mean absolute percent error
- Median absolute percent error
- WAPE: this metric explicitly weights the errors with the scale of the timestep. In many cases the weight is the quantity of observation, but it can take any other values. This metric is different from ND in that ND aggregates across multiple time series, but WAPE is weighted across timesteps.

__Symmetric error__ = $\frac{200(y_t - \hat{y_t})}{|y_t| + |\hat{y_t}|}$: this error is an alternative to percent error that fixes the asymmetrical problem with the percent error. Note that even symmetric error in some cases is also asymmetrical. Metrics based on this error are:
- Symmetric mean absolute percent error
- Symmetric median absolute percent error

__Other intrinsic metrics__

There are some other metrics that are intrinsic in nature, but don't confirm the other metrics. Among which are the following:
- Cumulative forecast error = $\sum (y_t - \hat{y_t})$: is the sum of all the errors, including the sign of the error. It measures the degree of over and under forecasting, and is scaled-dependent. This metric helps to understand whether a forecast is consistently over or under forecasting over a given horizon. 
- Forecast bias. This is a scale-independent metric that can be used for comparing time series, or investigating over and under forecasting across time series.
- Tracking signal: this metric is also used for measuring over and under forecasting, and is used in an online setting.  It helps us detect structural biases in the forecasting model. Typically, the Tracking Signal is used along with a threshold value so that going above or below (usually the threshold value used is 3.75) it throws a warning.

### Extrinsic metrics
There are two major buckets of metrics under the extrinsic umbrella â€“ relative error and scaled error.

__Relative error__

__Scaled error__


## Guidelines for choosing a metric

## Validation strategies for evaluating forecasts
Validation strategy is another important integral part of a time series forecasting. Due to temporal characteristics of a time series data, it is not possible to use conventional machine learning approaches to evaluate a trained model. For a time series data, standard assumption od i.i.d. does not hold true. There are two main paradigms of validation: in-sample and out-of-sample validations. While in-sample validation used to be the standard method for classical statistical models, modern machine learning models almost all employ out-of-sample validation. For out-of-sample validation, there are two major schools  of thoughts: 1. holdout-based strategies and 2- cross-validation- based strategies.

### holdout strategies
Summary: In this approach, we sample an original point in the time series (preferably toward the end of the series), such that the portion of the time series after that point is shorter than the portion before it. Via either rolling window or expanding method, we generate a training and validation split. Train the model on training, and test it on the hold-out validation split. 
There are three aspects of a holdout strategy, and they can be mixed and matched to create many variations of the strategy. The three aspects are as follows:

1. Sampling strategy â€“ A sampling strategy is how we sample the validation split(s) from training data. This method picks  one or more points in the time series and based on the predefined length of the validation $L_v$ parameter, it extracts that piece of data from the time series dataset.
2. Window strategy â€“ A window strategy decides how we sample the window of training split(s) from training data. Two approaches are used for selecting the windows:
  -  expanding window: the training split expands as the origin moves forward in time.
  -  rolling window: the length of the training split is constant and as we move the origin forward by $n$ timesteps, the training split drops $n$ timesteps from the start of the time series. __Note__ the window for validation set is independent of any other windows defined during the training process, including was used for feature engineering and preprocessing.

  Some key considerations:
  - Expanding window is a good setup for a short time series, where the expanding window leads to more data being available for the models.
  - Rolling window removes the oldest data from training. If the time series is non-stationary and the behavior is bound to change as time passes, having a rolling window will be beneficial to keep the model up to date.
  - When we use the expanding window strategy for repeated evaluation, such as in cross-validation, the increase in time series length used for training can introduce some bias toward windows with a longer history. The rolling window strategy takes care of that bias by maintaining the same length of the series.
  
3. Calibration strategy â€“ A calibration strategy decides whether a model should be recalibrated or not. The calibration strategy is only valid in cases where we do multiple evaluations with different origins. The calibration strategy is fixed at recalibrate because we are only testing and evaluating the model once.

   This method trains the model again with new training split for every origin. The retrained model is then used to evaluate the validation split. For the update strategy, the original trained model is used.

__Downside of holdout strategy__

This strategy relies on a single split of data to evaluate model performance. For non-stationary series, this can cause a problem since the selected model may capture the idiosyncrasies of the split that we have chosen.


__Sampling strategy__
To mitigate the issue with single holdout, repeating holdout strategy is employed. Scikit-learn has `sklearn.model_selection.PredefinedSplit` class to perform this approach. Also it has `TimeSeriesSplit` to perform a split.

This approach has several variants, including:
- with no overlap
- with overlap
- no overlap with gaps
 
### cross-validation strategies
The cross-validation method repeats the holdout evaluation multiple times, and measures the performance of a system by averaging the performance on different splits. This requires sampling multiple windows at random or using predefined windows as validation splits.

A similar approach to machine learning k-fold cross-validation, but developed for time series is the blocked cross-validation method [paper](https://doi.org/10.1007/978-3-642-61564-1_4). This method does not randomly shuffle the dataset before partitioning into k subsets (each of length $L_v$). Instead, the partitioning results in $k$ contiguous blocks of observation. Then, similar to the k-fold method, the train and test are performed, while temporal integrity of the problem is satisfied. To implement this method, we can employ the standard sklearn method, but set the shuffle to False. 

Similar to the holdout method, there is a variant of cross-validation with gaps. To implement this method, we need to manually code it. 


### How to pick the best validation strategy
[Ref](https://www.kaggle.com/code/konradb/ts-10-validation-methods-for-time-series)

Some guidelines for picking a validation strategy:
- the validation strategy needs to be aligned with the real use of the model. For example, if the model is going to be used for predicting the next 60 days, the validation set also needs  to have a length of 60 days.
- A preferred method in general is repeating holdout strategy.
- For a pure autoregressive formulation of a stationary time series, regular k-fold method shows better performance than holdout methods [ref](https://www.sciencedirect.com/science/article/abs/pii/S0020025511006773). 
- Blocked-cross-validation is better alternative than other cross-validation methods [ref](https://doi.org/10.1007/s10994-020-05910-7)
- For a non-stationary time series, repeating hold-out strategy performs the best [ref]()
- For a short time series, blocked-cross-validation (after taking the time series stationary) performs the best.
- For time series with exogenous variables, holdout strategies perform better than other methods.
- Models that use some kind of memory of the past such as exponential smoothing or RNN, cross-validation does not perform well.
- For a strong seasonal time series, the validation period needs to mimic the forecast horizon for the best performance.

### Validation strategies for a dataset with multiple time series

For a dataset with multiple time series, developing a validation strategy requires some additional considerations. Some options to adopt validation strategy for the datasets with multiple time series are:
- loop over the different time series and use the appropriate validation strategy for training. They concatenate the results across time series.
- code a custom group split class by employing datetime or time index (similar to strategies for global deep learning methods) as  the group. Then use a repeating holdout strategy.
- The window for different time series requires consistency in length.


---
---




---
<h1> Cyclic time serie </h1>
A time series can be constituted of a set of the multi-dimensional feature vectors ordered according to the time occurrence of the vectors.

In a holistic view, there are three different ways to model dynamic contents of time series: deterministic, chaotic and stochastic models. 
- With deterministic models, time series can be expressed by a closed mathematical formula. A deterministic system is completely described by a linear time invariant differential equation. . 
- Chaotic time series are constituted of a nonlinear differential equation, with an unknown initial condition. Here the output time series is the solution to a nonlinear differential equation with an unknown initial condition. Initial conditions are crucial in forecasting a chaotic time series. By knowing the initial conditions, one can completely find the output time series. This makes the initial condition in a chaotic time series system an important piece of information.
- In stochastic models, an output time series is assumed to have resulted from a nonlinear and time dependent differential equation. We cannot fully define a linear time invariant differential equation for the system, so the solution of the system is not uniquely identified. A complete solution cannot be found for the output, and therefore, an optimization technique must be invoked for the system identification.

To formulate a model time series analysis, in simplest form a set of events occuring in the past and present are used to predict the future events. Any $m$ dimensional series then can be decomposed into $m$ univariate series. It is often the case that the time series is sliced into the temporal windows of L samples, and the model parameters are found by utilizing contents of each window, sliding over the time series with an overlap of V samples between each two successive windows. Root mean square of the predicted error, defined as the difference between actual values of time series and the predicted ones, can be employed as an informative metric to find an understanding about the model capability in identifying time series.

__Variation in time series__

There are two types of variation in time series analysis:
- Variation of the time series values for a certain subject with respect to time, t
- Variation of the time series value at a certain time point with respect to the subjects, i





A group of stationary time series whose temporal statistics are equal to their population statistics (counter moments) is known as ergodic time series. 

__Cyclic time series__

A type of stochastic time-series, its values resemble repetitive contents, but cannot be categorized as periodic time series. A periodic time series is predictable, which is not possible in the case of stochastic time series. In these cases, even though regularity cannot be observed in the value of time series, meaning that the values are not exactly repeated at a certain, priory known points of the time. Nevertheless, certain patterns are repetitively seen over a time span. These types of time series are named as cyclic time series. Electrocardiogram is an example of a cyclic time series.

A cyclic model for processing a time series assumes that the time series resembles random behavior within the cycles, and also the cycle duration by itself is also a random variable. In many practical cases, an auxiliary signal is recorded along with the time series synchronously. The auxiliary signal helps to identify the onset and the endpoint information of the time series.


