<h1>Stochastic time series - from foudnation to edge approaches</h1>

Last update: 07/2024

# Time series - overview
__References__:
- [A Survey on Principles, Models and Methods for Learning from Irregularly Sampled Time Series: From Discretization to Attention and Invariance](https://arxiv.org/abs/2012.00168)
- [Learning from Irregularly-Sampled Time Series: A Missing Data Perspective](https://arxiv.org/abs/2008.07599)


This summary goes beyound classical methods such as ARIMA, and starts with modern machine learning and deep learning techniques. However, some priliminary terms are common in time series analysis, no matter what techniques is employed.

A __time series__ is a set of observations taken sequentially in time. This implies, if we record the same observation over time, we end up with a time series dataset. Two main types of time series are regular (recording at a regular interval) and iregular time series. The techniques in thsi summary covers regular time series. 

In terms of tasks, there are three broadly applications for time series analysis: time series forecating, time series classification, and interpretation and causality. The focus of this summary is the first two applications. Causality and interpretations are covered in another summary under causal machine learning repository.

__Data-generating process__ is the underlying process that generates a time series. Often, the DGP is generated by a stochastic process. In real world, an approximation of DGP is feasible, which is performed by a model. The model is a representation of some essential aspect of reality (DGP). While all models are unrealistic, some are useful. Differnt type of __models__ are used based on situation and objective. 

## different types of time series

__White noise__: a sequence of random numbers with zero mean and constant standard deviation.

__Red noise__: a sequence of random numbers with  has zero mean and constant variance but is serially correlated in time.

Example: $x_{t+1} = rx_t + (1-r^2)^{0.5}  w$, where $w$ is random sample from a white noise distribution and $r$ is a correlation coefficient.

__Seasonal or cyclical signal__: the most common signal in a time series.

__Autoregressive signals__: refers to when the value of a time series for the current timestep is dependent on the values of the time series in the previous timesteps. This serial correlation is a key property of the AR signal, and it is parametrized by Order of serial correlation (number of previous timesteps that the signal is dependent on), and coefficient to combine the previous timesteps.


__Combination of the previous time series__

A combination of two or more series in the above, can also generate a time series. As an example, a pseudo-periodic signal with white noise and combine it with an AR signal generates a new time series.

__Stationary and non-stationary time series__

A time series is stationary when the probability distribution remains the same at every point in time.  A time series defined by standard Gaussian distribution can become non-stationary if over time the mean changes, or the variance changes.

While stationary time sereis is an assumption for many models, in the real world, most time series are non-stationary. 

Example of non-stationary time series
- Change in mean shows itself when we have an upward or downward trend. 
- A time series with seasonality is also non-stationary. 
- Change in variance shows itself when a time series has fluctuating variance. An example is heteroscedasticity, in which time series starts with low variance, and variance keeps getting bigger over time.

## Predictability of a time series
It is also notable, time series are not all predictable. An example is stock price. Efficient-market hypothesis (EMH) implies  all known information about a stock price is already factored into the price of the stock. The implication of the hypothesis is that if someone can forecast accurately, many others will also be able to do that, and thereby the market price of the stock already reflects the change in price that this forecast brought about.

Three factors that helps to determine predictability of a time series are:
- understaing the DGP
- amount of data
- adeduatley repeating pattern

## Forecasting terminologies
- __Forecasting__: predicting the future values of a time series, with the knowledge of past (either past values and/or other related varables)
- __Multivariate forecasting__: if the problem in hand has more than one time series, that have dependencies among each other. 
- __Explanatory forecasting__: using information other than the history of a variable values, to perform forecasting task.
- __Backtesting__:the equivalent of validation, here we use the history to evaluate a trained model. 
- __In-sample and out-sample__: in sample refers to training data, and out-sample refers to testing data. 
- __Exogenous and endogenous variables__: Exogenous variables are parallel time series variables that are not modeled directly for output but used for modeling the time series that we are interested in. Endogenous variables are variables that are affected by other variables in the system. A purely endogenous variable is a variable that is entirely dependent on the other variables in the system. 
- __Forecast combination__: similar to ensembling in machine learning, is a process by which a function (either heuristic or learned) is used to combine multiple forecast. 


# Processing time series
__References__
- []()
- []()
- []()

























































---
<h1> Cyclic time serie </h1>
A time series can be constituted of a set of the multi-dimensional feature vectors ordered according to the time occurrence of the vectors.

In a holistic view, there are three different ways to model dynamic contents of time series: deterministic, chaotic and stochastic model. 
- With a deterministic models, time series can be expressed by a closed mathematical formula. A deterministic system is completely described by a linear time invariant differential equation. . 
- Chaotic time series are constituted of a nonlinear differential equation, with an unknown initial condition. Here the output time series is the solution to a nonlinear differential equation with an unknown initial condition. Initial condition is cruitial in forecasting a chaotic time series. By knowing the initial conditions, one can completely find the output time series. This makes the initial condition in chaotic time series system an important piece of infrmation.
- In stochastic models, an output time series is assumed to have resulted from a nonlinear and time dependent differential equations. We cannot fully define a linear time invariant differential equation for the system, so the solution of the system is not uniquely identified. A complete solution cannot be found for the output, and therefore, an optimization technique must be invoked for the system identification.

To formulate a model time series analysis, in simplest form a set of events occuring in the past and present are used to predict the future events. Any $m$ dimensional series then can be decomposed into $m$ univariate series. It is often the case that the time series is sliced into the temporal windows of L samples, and the model parameters are found by utilising contents of each window, sliding over the time series with an overlap of V samples between each two successive windows. Root mean square of the predicted error, defined as the difference between actual values of time series and the predicted ones, can be employed as an informative metric to find an understanding about the model capability in identifying time series.

__Variation in time series__

There are two types of variation in time series analysis:
- Variation of the time series values for a certain subject with respect to time, t
- Variation of the time series value at a certain time point with respect to the subjects, i





A group of stationary time series whose temporal statistics are equal to their population statistics (counter moments) is known as ergodic time series. 

__Cyclic time series__

A type of stochastic time-series, its values resemble repetitive contents, but cannot be categorized as periodic time series. A periodict time series is predictable, which is not possible in the case of stochastic time series. In these cases, even though regularity cannot be observed in the value of time series, meaning that the values are not exactly repeated at a certain, priory known points of the time. Nevertheless, certain patterns are repetitively seen over a time span. These types of time series are named as cyclic time series. Electrocardiogram is an example of cyclic time series.

A cyclic model for processing a time series assumes that the time series resembles random behaviour within the cycles, and also the cycle duration by itself is also a random variable. In many practical cases, an auxiliary signal is recorded along with the time series synchronously. The auxiliary signal helps to identify the onset and the endpoint information of the time series.
